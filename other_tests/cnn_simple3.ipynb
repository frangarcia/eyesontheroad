{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-02T13:08:00.224128600Z",
     "start_time": "2023-06-02T13:07:57.011081800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 16:53:50.161374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.compat.v2.__internal__' has no attribute 'dispatch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_model\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m  Dense, Flatten, Conv2D, Rescaling, BatchNormalization, MaxPooling2D, Dropout\n",
      "File \u001B[0;32m~/anaconda3/envs/keras/lib/python3.9/site-packages/keras/__init__.py:21\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \n\u001B[1;32m     17\u001B[0m \u001B[38;5;124;03mDetailed documentation and user guides are available at\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;124;03m[keras.io](https://keras.io).\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute\n\u001B[0;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m models\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minput_layer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Input\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msequential\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n",
      "File \u001B[0;32m~/anaconda3/envs/keras/lib/python3.9/site-packages/keras/models/__init__.py:18\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# ==============================================================================\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Functional\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msequential\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtraining\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Model\n",
      "File \u001B[0;32m~/anaconda3/envs/keras/lib/python3.9/site-packages/keras/engine/functional.py:26\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtensor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m layout_map \u001B[38;5;28;01mas\u001B[39;00m layout_map_lib\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m base_layer\n",
      "File \u001B[0;32m~/anaconda3/envs/keras/lib/python3.9/site-packages/keras/backend.py:32\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m---> 32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend_config\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute_coordinator_utils \u001B[38;5;28;01mas\u001B[39;00m dc\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtensor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dtensor_api \u001B[38;5;28;01mas\u001B[39;00m dtensor\n",
      "File \u001B[0;32m~/anaconda3/envs/keras/lib/python3.9/site-packages/keras/backend_config.py:33\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# Default image data format, one of \"channels_last\", \"channels_first\".\u001B[39;00m\n\u001B[1;32m     29\u001B[0m _IMAGE_DATA_FORMAT \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchannels_last\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;129m@keras_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.backend.epsilon\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 33\u001B[0m \u001B[38;5;129m@tf\u001B[39m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__internal__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch\u001B[49m\u001B[38;5;241m.\u001B[39madd_dispatch_support\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mepsilon\u001B[39m():\n\u001B[1;32m     35\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Returns the value of the fuzz factor used in numeric expressions.\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \n\u001B[1;32m     37\u001B[0m \u001B[38;5;124;03m    Returns:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;124;03m    1e-07\u001B[39;00m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _EPSILON\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'tensorflow.compat.v2.__internal__' has no attribute 'dispatch'"
     ]
    }
   ],
   "source": [
    "# pip install -U scikit-learn\n",
    "# pip install matplotlib\n",
    "# pip install Pillow\n",
    "# pip install seaborn\n",
    "# pip install opencv-python\n",
    "# pip install mtcnn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import  Dense, Flatten, Conv2D, Rescaling, BatchNormalization, MaxPooling2D, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random\n",
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "FOLDER_IMAGES = './datasets/dmd/binary_labels'\n",
    "INPUT_SHAPE = (180, 180, 3)\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (180, 180)\n",
    "VAL_SPLIT = 0.2\n",
    "MODEL_SAVE_FOLDER = './models/cnn/cnn_simple/'\n",
    "EPOCHS = 30"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T13:08:03.262803500Z",
     "start_time": "2023-06-02T13:08:03.224801800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def show_random_images_from_folder(folder_path, num_images=5):\n",
    "    image_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path)\n",
    "                   if os.path.isfile(os.path.join(folder_path, filename))]\n",
    "    random.shuffle(image_paths)\n",
    "    selected_image_paths = image_paths[:num_images]\n",
    "    num_cols = min(num_images, 5)\n",
    "    num_rows = (num_images - 1) // num_cols + 1\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 8))\n",
    "    axes = np.reshape(axes, (num_rows, num_cols))  # Reshape axes to have desired rows and columns\n",
    "    for i, image_path in enumerate(selected_image_paths):\n",
    "        img = Image.open(image_path)\n",
    "        ax = axes[i // num_cols, i % num_cols]\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "    if num_images < num_rows * num_cols:\n",
    "        for i in range(num_images, num_rows * num_cols):\n",
    "            fig.delaxes(axes[i // num_cols, i % num_cols])\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def show_images_from_dataframe(data_frame, num_images = 5):\n",
    "    for images, labels in data_frame(num_images):\n",
    "        numpy_images = images.numpy()\n",
    "        for image in numpy_images:\n",
    "            plt.imshow(image.astype(\"uint8\"))  # Convert back to uint8 for visualization\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "def crop_face_from_image(image):\n",
    "    detector = MTCNN()\n",
    "    faces = detector.detect_faces(image)\n",
    "    highlighted_image = image.copy()\n",
    "    ax = plt.gca()\n",
    "    y_min = float('inf')\n",
    "    y_max = float('-inf')\n",
    "    x_min = float('inf')\n",
    "    x_max = float('-inf')\n",
    "    for face in faces:\n",
    "        x, y, width, height = face['box']\n",
    "        face_border = Rectangle((x, y), width, height, fill=False, color='red')\n",
    "        ax.add_patch(face_border)\n",
    "        y_min = min(y_min, y)\n",
    "        y_max = max(y_max, y + height)\n",
    "        x_min = min(x_min, x)\n",
    "        x_max = max(x_max, x + width)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    if y_min == float('inf') or y_max == float('-inf') or x_min == float('inf') or x_max == float('-inf'):\n",
    "        return highlighted_image\n",
    "    y_min = max(0, y_min)\n",
    "    y_max = min(image.shape[0], y_max)\n",
    "    x_min = max(0, x_min)\n",
    "    x_max = min(image.shape[1], x_max)\n",
    "    cropped_image = highlighted_image[int(y_min):int(y_max), int(x_min):int(x_max)]\n",
    "    plt.imshow(cropped_image.astype(\"uint8\"))\n",
    "    return cropped_image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T13:08:07.945931900Z",
     "start_time": "2023-06-02T13:08:07.910593700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.utils' has no attribute 'image_dataset_from_directory'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_ds \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage_dataset_from_directory\u001B[49m(\n\u001B[1;32m      2\u001B[0m   FOLDER_IMAGES,\n\u001B[1;32m      3\u001B[0m   validation_split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m,\n\u001B[1;32m      4\u001B[0m   subset\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      5\u001B[0m   seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m123\u001B[39m,\n\u001B[1;32m      6\u001B[0m   image_size\u001B[38;5;241m=\u001B[39mIMG_SIZE,\n\u001B[1;32m      7\u001B[0m   batch_size\u001B[38;5;241m=\u001B[39mBATCH_SIZE)\n\u001B[1;32m      9\u001B[0m val_ds \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mimage_dataset_from_directory(\n\u001B[1;32m     10\u001B[0m   FOLDER_IMAGES,\n\u001B[1;32m     11\u001B[0m   validation_split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     14\u001B[0m   image_size\u001B[38;5;241m=\u001B[39mIMG_SIZE,\n\u001B[1;32m     15\u001B[0m   batch_size\u001B[38;5;241m=\u001B[39mBATCH_SIZE)\n\u001B[1;32m     17\u001B[0m class_names \u001B[38;5;241m=\u001B[39m train_ds\u001B[38;5;241m.\u001B[39mclass_names\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'tensorflow.keras.utils' has no attribute 'image_dataset_from_directory'"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  FOLDER_IMAGES,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=IMG_SIZE,\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  FOLDER_IMAGES,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=IMG_SIZE,\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(class_names)\n",
    "\n",
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T14:54:35.404471404Z",
     "start_time": "2023-06-01T14:54:35.400053090Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.exists(MODEL_SAVE_FOLDER):\n",
    "    model = keras.models.load_model(MODEL_SAVE_FOLDER + 'best.h5')\n",
    "else:\n",
    "    model = keras.models.Sequential([\n",
    "        #normalization\n",
    "        Rescaling(1./255, input_shape=INPUT_SHAPE),\n",
    "\n",
    "        Conv2D(filters=32, kernel_size=5, strides=1, activation='relu'),\n",
    "        Conv2D(filters=32, kernel_size=5, strides=1, activation='relu', use_bias=False),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(strides=2),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Conv2D(filters=64, kernel_size=3, strides=1, activation='relu'),\n",
    "        Conv2D(filters=64, kernel_size=3, strides=1, activation='relu', use_bias=False),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(strides=2),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(units=256, activation='relu', use_bias=False),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        Dense(units=128, use_bias=False, activation='relu'),\n",
    "\n",
    "        Dense(units=84, use_bias=False, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(num_classes, name=\"outputs\")\n",
    "    ])\n",
    "\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3)\n",
    "\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=MODEL_SAVE_FOLDER + 'best.h5',\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=32,\n",
    "        callbacks=[model_checkpoint]\n",
    "    )\n",
    "\n",
    "    with open(MODEL_SAVE_FOLDER + 'model_history.pkl', 'wb') as file:\n",
    "        pickle.dump(history.history, file)\n",
    "\n",
    "with open(MODEL_SAVE_FOLDER + 'model_history.pkl', 'rb') as file:\n",
    "    history = pickle.load(file)\n",
    "    print(history)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model = load_model(MODEL_SAVE_FOLDER + 'best.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "with open(MODEL_SAVE_FOLDER + 'best.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc = history['accuracy']\n",
    "val_acc = history['val_accuracy']\n",
    "\n",
    "loss = history['loss']\n",
    "val_loss = history['val_loss']\n",
    "\n",
    "epochs_range = range(30)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Select 5 random images\n",
    "random_images = random.sample(glob('./datasets/dmd/binary_labels_test/*.jpg'), 5)\n",
    "\n",
    "# Create a grid of subplots\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "for i, image_path in enumerate(random_images):\n",
    "    img = tf.keras.utils.load_img(image_path, target_size=IMG_SIZE)\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, 0)  # Create a batch\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "    ax = axes[i]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(\"Predicted: {} (Confidence: {:.2f}%)\".format(class_names[np.argmax(score)], 100 * np.max(score)))\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "\n",
    "# Obtain predictions for the test data\n",
    "predictions = model.predict(val_ds)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
